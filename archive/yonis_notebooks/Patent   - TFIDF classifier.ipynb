{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1688217785202,
     "user": {
      "displayName": "Jonathan Vulcan",
      "userId": "13528297572882345759"
     },
     "user_tz": -180
    },
    "id": "TzXl7MbWw4yN"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from google.colab import drive\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3705,
     "status": "ok",
     "timestamp": 1688217766981,
     "user": {
      "displayName": "Jonathan Vulcan",
      "userId": "13528297572882345759"
     },
     "user_tz": -180
    },
    "id": "tbV4PyZOxScC",
    "outputId": "92f4f3b9-8bd2-4bf3-fa2f-d12290e6a15a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive/', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5869,
     "status": "ok",
     "timestamp": 1688217793475,
     "user": {
      "displayName": "Jonathan Vulcan",
      "userId": "13528297572882345759"
     },
     "user_tz": -180
    },
    "id": "LVW43u4vxZ5w",
    "outputId": "8d1555d1-92d8-4b1c-e89e-e44fb40d6c13"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-78-7ba450f1f037>:1: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(r'/content/gdrive/MyDrive/patent project/clean_data_with_enrich.csv',dtype={'filing_year':'str'})\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'/content/gdrive/MyDrive/patent project/clean_data_with_enrich.csv',dtype={'filing_year':'str'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1688217774870,
     "user": {
      "displayName": "Jonathan Vulcan",
      "userId": "13528297572882345759"
     },
     "user_tz": -180
    },
    "id": "wfpQLChPyo2-",
    "outputId": "1b5f8a04-c97d-4341-dc17-1c21cc8db493"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-ac634f15-5eb6-4cc9-bf03-1e9e68844bc8\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>application_number</th>\n",
       "      <th>uspc_class</th>\n",
       "      <th>one_if_male</th>\n",
       "      <th>one_if_female</th>\n",
       "      <th>filing_year</th>\n",
       "      <th>one_if_patented</th>\n",
       "      <th>one_if_abandoned</th>\n",
       "      <th>one_if_pending</th>\n",
       "      <th>one_if_small</th>\n",
       "      <th>Biotechnology</th>\n",
       "      <th>...</th>\n",
       "      <th>words_per_sentence</th>\n",
       "      <th>sentences_per_paragraph</th>\n",
       "      <th>type_token_ratio</th>\n",
       "      <th>syllables</th>\n",
       "      <th>sentences</th>\n",
       "      <th>long_words</th>\n",
       "      <th>complex_words</th>\n",
       "      <th>Gender_Target</th>\n",
       "      <th>Patent_Target</th>\n",
       "      <th>Parent_Catgeory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13054882</td>\n",
       "      <td>701</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.250000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.504587</td>\n",
       "      <td>183.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>patented</td>\n",
       "      <td>Trans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13260099</td>\n",
       "      <td>424</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>37.666667</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.530973</td>\n",
       "      <td>199.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>abandoned</td>\n",
       "      <td>Biotechnology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13261421</td>\n",
       "      <td>424</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>77.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>patented</td>\n",
       "      <td>Biotechnology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13261486</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.653061</td>\n",
       "      <td>282.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>patented</td>\n",
       "      <td>Chem_Material_Engr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13261494</td>\n",
       "      <td>362</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>45.666667</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.583942</td>\n",
       "      <td>200.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>patented</td>\n",
       "      <td>Semis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac634f15-5eb6-4cc9-bf03-1e9e68844bc8')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-ac634f15-5eb6-4cc9-bf03-1e9e68844bc8 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-ac634f15-5eb6-4cc9-bf03-1e9e68844bc8');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   application_number uspc_class  one_if_male  one_if_female filing_year  \\\n",
       "0            13054882        701            1              0        2013   \n",
       "1            13260099        424            1              0        2013   \n",
       "2            13261421        424            1              0        2013   \n",
       "3            13261486        136            1              0        2013   \n",
       "4            13261494        362            1              0        2013   \n",
       "\n",
       "   one_if_patented  one_if_abandoned  one_if_pending  one_if_small  \\\n",
       "0                1                 0               0             0   \n",
       "1                0                 1               0             0   \n",
       "2                1                 0               0             1   \n",
       "3                1                 0               0             1   \n",
       "4                1                 0               0             1   \n",
       "\n",
       "   Biotechnology  ...  words_per_sentence  sentences_per_paragraph  \\\n",
       "0              0  ...           27.250000                      4.0   \n",
       "1              1  ...           37.666667                      3.0   \n",
       "2              1  ...           19.000000                      2.0   \n",
       "3              0  ...           49.000000                      3.0   \n",
       "4              0  ...           45.666667                      3.0   \n",
       "\n",
       "   type_token_ratio  syllables  sentences  long_words  complex_words  \\\n",
       "0          0.504587      183.0        4.0        35.0           28.0   \n",
       "1          0.530973      199.0        3.0        36.0           26.0   \n",
       "2          0.736842       77.0        2.0        21.0           16.0   \n",
       "3          0.653061      282.0        3.0        67.0           51.0   \n",
       "4          0.583942      200.0        3.0        39.0           25.0   \n",
       "\n",
       "  Gender_Target Patent_Target     Parent_Catgeory  \n",
       "0          Male      patented               Trans  \n",
       "1          Male     abandoned       Biotechnology  \n",
       "2          Male      patented       Biotechnology  \n",
       "3          Male      patented  Chem_Material_Engr  \n",
       "4          Male      patented               Semis  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1688217774871,
     "user": {
      "displayName": "Jonathan Vulcan",
      "userId": "13528297572882345759"
     },
     "user_tz": -180
    },
    "id": "20xvV6RGx1XL"
   },
   "outputs": [],
   "source": [
    "gender_df = df[['clean_abstract','Gender_Target']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jaYnEAu80gEr"
   },
   "source": [
    "Check Top 20 words by Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1688217774871,
     "user": {
      "displayName": "Jonathan Vulcan",
      "userId": "13528297572882345759"
     },
     "user_tz": -180
    },
    "id": "mnr8z8sA0wS6"
   },
   "outputs": [],
   "source": [
    "def get_ngrams(data, n, g):\n",
    "    vec = CountVectorizer(ngram_range=(g, g)).fit(data)\n",
    "    bag_of_words = vec.transform(data) #sparse matrix of count_vectorizer\n",
    "    sum_words = bag_of_words.sum(axis=0) #total number of words\n",
    "    sum_words = np.array(sum_words)[0].tolist() #convert to list\n",
    "    words_freq = [(word, sum_words[idx]) for word, idx in vec.vocabulary_.items()] #get word freqency for word location in count vec\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True) #key is used to perform sorting using word_freqency\n",
    "    return words_freq[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "executionInfo": {
     "elapsed": 2325,
     "status": "error",
     "timestamp": 1688217777185,
     "user": {
      "displayName": "Jonathan Vulcan",
      "userId": "13528297572882345759"
     },
     "user_tz": -180
    },
    "id": "3eqQ4nr_1QC8",
    "outputId": "74314340-82e0-42ef-f0b6-a7ab78cb349c"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-891caa46fbf6>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#female unigrams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfemale_unigrams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgender_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgender_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Gender_Target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'Female'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_abstract'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-75-7107d498c1d0>\u001b[0m in \u001b[0;36mget_ngrams\u001b[0;34m(data, n, g)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mbag_of_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#sparse matrix of count_vectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0msum_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbag_of_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#total number of words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msum_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#convert to list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_documents)\u001b[0m\n\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m         \u001b[0;31m# use the same matrix-building strategy as fit_transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1433\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1434\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1273\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1275\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1276\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mngrams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstop_words\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#female unigrams\n",
    "female_unigrams = get_ngrams(gender_df[gender_df['Gender_Target']=='Female']['clean_abstract'],50,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "aborted",
     "timestamp": 1688217777187,
     "user": {
      "displayName": "Jonathan Vulcan",
      "userId": "13528297572882345759"
     },
     "user_tz": -180
    },
    "id": "q4W_mB414ZJb"
   },
   "outputs": [],
   "source": [
    "male_unigrams = get_ngrams(gender_df[gender_df['Gender_Target']=='Male']['clean_abstract'],50,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "aborted",
     "timestamp": 1688217777187,
     "user": {
      "displayName": "Jonathan Vulcan",
      "userId": "13528297572882345759"
     },
     "user_tz": -180
    },
    "id": "-WR7x8T44dbY"
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "#only in female\n",
    "for m_word in female_unigrams:\n",
    "  if m_word[0] not in  list(map(operator.itemgetter(0), male_unigrams)):\n",
    "    print(m_word[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "aborted",
     "timestamp": 1688217777188,
     "user": {
      "displayName": "Jonathan Vulcan",
      "userId": "13528297572882345759"
     },
     "user_tz": -180
    },
    "id": "cejwpnkJ5bI3"
   },
   "outputs": [],
   "source": [
    "for m_word in male_unigrams:\n",
    "  if m_word[0] not in  list(map(operator.itemgetter(0), female_unigrams)):\n",
    "    print(m_word[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "aborted",
     "timestamp": 1688217777188,
     "user": {
      "displayName": "Jonathan Vulcan",
      "userId": "13528297572882345759"
     },
     "user_tz": -180
    },
    "id": "ispryS226UU9"
   },
   "outputs": [],
   "source": [
    "#get bigrams\n",
    "female_bigrams = get_ngrams(gender_df[gender_df['Gender_Target']=='Female']['clean_abstract'],50,2)\n",
    "male_bigrams = get_ngrams(gender_df[gender_df['Gender_Target']=='Male']['clean_abstract'],50,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "aborted",
     "timestamp": 1688217777188,
     "user": {
      "displayName": "Jonathan Vulcan",
      "userId": "13528297572882345759"
     },
     "user_tz": -180
    },
    "id": "d-uTsh8p6uRI"
   },
   "outputs": [],
   "source": [
    "for m_word in female_bigrams:\n",
    "  if m_word[0] not in  list(map(operator.itemgetter(0), male_bigrams)):\n",
    "    print(m_word[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "aborted",
     "timestamp": 1688217777189,
     "user": {
      "displayName": "Jonathan Vulcan",
      "userId": "13528297572882345759"
     },
     "user_tz": -180
    },
    "id": "_Ec-2oZ86yGF"
   },
   "outputs": [],
   "source": [
    "for m_word in male_bigrams:\n",
    "  if m_word[0] not in  list(map(operator.itemgetter(0), female_bigrams)):\n",
    "    print(m_word[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AOMHhX2r9vjF"
   },
   "source": [
    "**TFIDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "aborted",
     "timestamp": 1688217777190,
     "user": {
      "displayName": "Jonathan Vulcan",
      "userId": "13528297572882345759"
     },
     "user_tz": -180
    },
    "id": "Zp1mPAUQ9y1r"
   },
   "outputs": [],
   "source": [
    "gender_df['Gender_Target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "aborted",
     "timestamp": 1688217777190,
     "user": {
      "displayName": "Jonathan Vulcan",
      "userId": "13528297572882345759"
     },
     "user_tz": -180
    },
    "id": "_LGMswUYCjbv"
   },
   "outputs": [],
   "source": [
    "gender_df['Gender_Target'] = gender_df['Gender_Target'].apply(lambda x: 1 if x =='Female' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "aborted",
     "timestamp": 1688217777191,
     "user": {
      "displayName": "Jonathan Vulcan",
      "userId": "13528297572882345759"
     },
     "user_tz": -180
    },
    "id": "ptTwSkzoCbQK"
   },
   "outputs": [],
   "source": [
    "#lr classfier\n",
    "word_dict = {}\n",
    "for i in range(9):\n",
    "  only_male = gender_df.loc[gender_df['Gender_Target']==0,:].sample(26200)\n",
    "  only_female = gender_df.loc[gender_df['Gender_Target']==1,:]\n",
    "  all_data = pd.concat([only_male,only_female],ignore_index=True)\n",
    "  tfidf_vect = TfidfVectorizer(ngram_range=(1,2))\n",
    "  train, test= train_test_split(all_data, test_size=0.2, random_state=42)\n",
    "  Xtrain, ytrain = train['clean_abstract'], train['Gender_Target']\n",
    "  Xtest, ytest = test['clean_abstract'], test['Gender_Target']\n",
    "  Xtrain_tfidf = tfidf_vect.fit_transform(Xtrain)\n",
    "  Xtest_tfidf = tfidf_vect.transform(Xtest)\n",
    "  lr = LogisticRegression(max_iter=1000)\n",
    "  vocab = tfidf_vect.vocabulary_\n",
    "  feature_names = {v: k for k, v in vocab.items()}\n",
    "  lr.fit(Xtrain_tfidf,ytrain)\n",
    "  lr.fit(Xtrain_tfidf,ytrain)\n",
    "  p1=lr.predict(Xtest_tfidf)\n",
    "  s1=accuracy_score(ytest,p1)\n",
    "  print(\"Logistic Regression Accuracy :\", \"{:.2f}%\".format(100*s1))\n",
    "  coef = lr.coef_[0]\n",
    "  features = sorted([(feature_names[idx], coef[idx]) for idx in range(len(coef))], key=lambda x: x[1], reverse=True)\n",
    "  for feature in features[:20]:\n",
    "    print(feature)\n",
    "    if feature[0] in word_dict:\n",
    "      word_dict[feature[0]]+=1\n",
    "    else:\n",
    "      word_dict[feature[0]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "aborted",
     "timestamp": 1688217777191,
     "user": {
      "displayName": "Jonathan Vulcan",
      "userId": "13528297572882345759"
     },
     "user_tz": -180
    },
    "id": "sYERbDY0K6uJ"
   },
   "outputs": [],
   "source": [
    "word_importence = sorted(word_dict.items(),key=lambda x: x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "aborted",
     "timestamp": 1688217777192,
     "user": {
      "displayName": "Jonathan Vulcan",
      "userId": "13528297572882345759"
     },
     "user_tz": -180
    },
    "id": "zQhubjHzLHp8"
   },
   "outputs": [],
   "source": [
    "word_importence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "aborted",
     "timestamp": 1688217777192,
     "user": {
      "displayName": "Jonathan Vulcan",
      "userId": "13528297572882345759"
     },
     "user_tz": -180
    },
    "id": "jTs5l5X2TKPi"
   },
   "outputs": [],
   "source": [
    "#only small\n",
    "only_small = df[df['one_if_small']==1][['clean_abstract','Gender_Target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "aborted",
     "timestamp": 1688217777192,
     "user": {
      "displayName": "Jonathan Vulcan",
      "userId": "13528297572882345759"
     },
     "user_tz": -180
    },
    "id": "FeRy-lYITmfX"
   },
   "outputs": [],
   "source": [
    "only_small['Gender_Target'] = only_small['Gender_Target'].apply(lambda x: 1 if x =='Female' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "aborted",
     "timestamp": 1688217777193,
     "user": {
      "displayName": "Jonathan Vulcan",
      "userId": "13528297572882345759"
     },
     "user_tz": -180
    },
    "id": "FHird8jDTtWc"
   },
   "outputs": [],
   "source": [
    "only_small['Gender_Target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "aborted",
     "timestamp": 1688217777193,
     "user": {
      "displayName": "Jonathan Vulcan",
      "userId": "13528297572882345759"
     },
     "user_tz": -180
    },
    "id": "_ebUW1FlUQY3"
   },
   "outputs": [],
   "source": [
    "#lr classfier\n",
    "word_dict = {}\n",
    "for i in range(7):\n",
    "  only_male = only_small.loc[gender_df['Gender_Target']==0,:].sample(19000)\n",
    "  only_female = only_small.loc[gender_df['Gender_Target']==1,:]\n",
    "  all_data = pd.concat([only_male,only_female],ignore_index=True)\n",
    "  tfidf_vect = TfidfVectorizer(ngram_range=(1,2))\n",
    "  train, test= train_test_split(all_data, test_size=0.2, random_state=42)\n",
    "  Xtrain, ytrain = train['clean_abstract'], train['Gender_Target']\n",
    "  Xtest, ytest = test['clean_abstract'], test['Gender_Target']\n",
    "  Xtrain_tfidf = tfidf_vect.fit_transform(Xtrain)\n",
    "  Xtest_tfidf = tfidf_vect.transform(Xtest)\n",
    "  lr = LogisticRegression(max_iter=1000)\n",
    "  vocab = tfidf_vect.vocabulary_\n",
    "  feature_names = {v: k for k, v in vocab.items()}\n",
    "  lr.fit(Xtrain_tfidf,ytrain)\n",
    "  lr.fit(Xtrain_tfidf,ytrain)\n",
    "  p1=lr.predict(Xtest_tfidf)\n",
    "  s1=accuracy_score(ytest,p1)\n",
    "  print(\"Logistic Regression Accuracy :\", \"{:.2f}%\".format(100*s1))\n",
    "  coef = lr.coef_[0]\n",
    "  features = sorted([(feature_names[idx], coef[idx]) for idx in range(len(coef))], key=lambda x: x[1], reverse=True)\n",
    "  for feature in features[:20]:\n",
    "    print(feature)\n",
    "    if feature[0] in word_dict:\n",
    "      word_dict[feature[0]]+=1\n",
    "    else:\n",
    "      word_dict[feature[0]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "aborted",
     "timestamp": 1688217777193,
     "user": {
      "displayName": "Jonathan Vulcan",
      "userId": "13528297572882345759"
     },
     "user_tz": -180
    },
    "id": "ixcAmCBSVs1K"
   },
   "outputs": [],
   "source": [
    "word_importence = sorted(word_dict.items(),key=lambda x: x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "aborted",
     "timestamp": 1688217777194,
     "user": {
      "displayName": "Jonathan Vulcan",
      "userId": "13528297572882345759"
     },
     "user_tz": -180
    },
    "id": "m_nfl9rjVuNh"
   },
   "outputs": [],
   "source": [
    "word_importence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "aborted",
     "timestamp": 1688217777194,
     "user": {
      "displayName": "Jonathan Vulcan",
      "userId": "13528297572882345759"
     },
     "user_tz": -180
    },
    "id": "nf9V1x9ZafI5"
   },
   "outputs": [],
   "source": [
    "#by category\n",
    "cat_list = set(df['Parent_Catgeory'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "aborted",
     "timestamp": 1688217777194,
     "user": {
      "displayName": "Jonathan Vulcan",
      "userId": "13528297572882345759"
     },
     "user_tz": -180
    },
    "id": "MyX2mxMkbRjN"
   },
   "outputs": [],
   "source": [
    "cat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "aborted",
     "timestamp": 1688217777195,
     "user": {
      "displayName": "Jonathan Vulcan",
      "userId": "13528297572882345759"
     },
     "user_tz": -180
    },
    "id": "r0p75ZfPcF-A"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "math.ceil(7.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "aborted",
     "timestamp": 1688217777195,
     "user": {
      "displayName": "Jonathan Vulcan",
      "userId": "13528297572882345759"
     },
     "user_tz": -180
    },
    "id": "ayKUVMtNbUAS"
   },
   "outputs": [],
   "source": [
    "cat_dict = {}\n",
    "for cat in cat_list:\n",
    "  word_dict = {}\n",
    "  cat_df = df[(df['one_if_small']==1) & (df['Parent_Catgeory']==cat)][['clean_abstract','Gender_Target']]\n",
    "  cat_df['Gender_Target'] = cat_df['Gender_Target'].apply(lambda x: 1 if x =='Female' else 0)\n",
    "  how_many_iter = math.ceil(cat_df[cat_df['Gender_Target']==0].shape[0]/cat_df[cat_df['Gender_Target']==1].shape[0])\n",
    "  sample_size = cat_df[cat_df['Gender_Target']==1].shape[0]\n",
    "  for i in range(how_many_iter):\n",
    "    print(cat,i)\n",
    "    only_male = cat_df.loc[cat_df['Gender_Target']==0,:].sample(sample_size)\n",
    "    only_female = cat_df.loc[cat_df['Gender_Target']==1,:]\n",
    "    all_data = pd.concat([only_male,only_female],ignore_index=True)\n",
    "    tfidf_vect = TfidfVectorizer(ngram_range=(1,2))\n",
    "    train, test= train_test_split(all_data, test_size=0.2, random_state=42)\n",
    "    Xtrain, ytrain = train['clean_abstract'], train['Gender_Target']\n",
    "    Xtest, ytest = test['clean_abstract'], test['Gender_Target']\n",
    "    Xtrain_tfidf = tfidf_vect.fit_transform(Xtrain)\n",
    "    Xtest_tfidf = tfidf_vect.transform(Xtest)\n",
    "    lr = LogisticRegression(max_iter=1000)\n",
    "    vocab = tfidf_vect.vocabulary_\n",
    "    feature_names = {v: k for k, v in vocab.items()}\n",
    "    lr.fit(Xtrain_tfidf,ytrain)\n",
    "    lr.fit(Xtrain_tfidf,ytrain)\n",
    "    p1=lr.predict(Xtest_tfidf)\n",
    "    s1=accuracy_score(ytest,p1)\n",
    "    print(\"Logistic Regression Accuracy :\", \"{:.2f}%\".format(100*s1))\n",
    "    coef = lr.coef_[0]\n",
    "    features = sorted([(feature_names[idx], coef[idx]) for idx in range(len(coef))], key=lambda x: x[1], reverse=True)\n",
    "    for feature in features[:20]:\n",
    "      print(feature)\n",
    "      if feature[0] in word_dict:\n",
    "        word_dict[feature[0]]+=1\n",
    "      else:\n",
    "        word_dict[feature[0]] = 1\n",
    "  cat_dict[cat]=word_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "aborted",
     "timestamp": 1688217777195,
     "user": {
      "displayName": "Jonathan Vulcan",
      "userId": "13528297572882345759"
     },
     "user_tz": -180
    },
    "id": "aID0QSR7liy7"
   },
   "outputs": [],
   "source": [
    "cat_dict['Mech_Engr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ug2_80lnSe7"
   },
   "source": [
    "Classifier to predict accpet and reject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "executionInfo": {
     "elapsed": 413,
     "status": "ok",
     "timestamp": 1688217818338,
     "user": {
      "displayName": "Jonathan Vulcan",
      "userId": "13528297572882345759"
     },
     "user_tz": -180
    },
    "id": "JIQ1sCpGneF7"
   },
   "outputs": [],
   "source": [
    "patented_df = df[(df['one_if_small']==1) & (df['Patent_Target']!='pending')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 297,
     "status": "ok",
     "timestamp": 1688217921738,
     "user": {
      "displayName": "Jonathan Vulcan",
      "userId": "13528297572882345759"
     },
     "user_tz": -180
    },
    "id": "hb2V3VS0oJJJ",
    "outputId": "80762cf9-3c1a-4cf7-d7d2-31f13b827f4e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    76829\n",
       "1    52239\n",
       "Name: Patent_Target, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patented_df['Patent_Target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 281,
     "status": "ok",
     "timestamp": 1688217917538,
     "user": {
      "displayName": "Jonathan Vulcan",
      "userId": "13528297572882345759"
     },
     "user_tz": -180
    },
    "id": "4-xPsdxzn-l7",
    "outputId": "c8e8059e-455a-4c58-d795-fd5a5a1a8f4c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-83-7bf1702e5176>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  patented_df['Patent_Target'] = patented_df['Patent_Target'].apply(lambda x: 1 if x =='abandoned' else 0)\n"
     ]
    }
   ],
   "source": [
    "patented_df['Patent_Target'] = patented_df['Patent_Target'].apply(lambda x: 1 if x =='abandoned' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "executionInfo": {
     "elapsed": 346,
     "status": "ok",
     "timestamp": 1688217955263,
     "user": {
      "displayName": "Jonathan Vulcan",
      "userId": "13528297572882345759"
     },
     "user_tz": -180
    },
    "id": "QP527K1MoTl5"
   },
   "outputs": [],
   "source": [
    "patented_df = patented_df[['clean_abstract','Patent_Target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 304,
     "status": "ok",
     "timestamp": 1688220011751,
     "user": {
      "displayName": "Jonathan Vulcan",
      "userId": "13528297572882345759"
     },
     "user_tz": -180
    },
    "id": "9nNYiDeaooXU",
    "outputId": "2cb13953-c3ef-4b30-a881-ab90b28daf55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    76829\n",
       "1    52239\n",
       "Name: Patent_Target, dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patented_df['Patent_Target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 198532,
     "status": "ok",
     "timestamp": 1688219551589,
     "user": {
      "displayName": "Jonathan Vulcan",
      "userId": "13528297572882345759"
     },
     "user_tz": -180
    },
    "id": "VEml0V2yohPM",
    "outputId": "25aef87c-6c16-460d-bff3-2a51cabf2aa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy : 62.99%\n",
      "('invention', 3.9130010823789623)\n",
      "('financial', 2.736853656698412)\n",
      "('made', 2.5591555485921273)\n",
      "('business', 2.5273199713182395)\n",
      "('mean', 2.496146017915021)\n",
      "('consumer', 2.443356551981419)\n",
      "('database', 2.2777069493933864)\n",
      "('comprised', 2.140733260460559)\n",
      "('offer', 2.0459905757409436)\n",
      "('social', 2.0002539621012443)\n",
      "('comprising', 1.9986432740109032)\n",
      "('owner', 1.9338253089357507)\n",
      "('adapted', 1.92790982961351)\n",
      "('power source', 1.9191900124668786)\n",
      "('fund', 1.9029070707504054)\n",
      "('providing', 1.8619879704605415)\n",
      "('portfolio', 1.8463438558595353)\n",
      "('consists', 1.8306093466649915)\n",
      "('rating', 1.8179135030269156)\n",
      "('medical', 1.7902813270614901)\n",
      "('brain', 1.7869774251152943)\n",
      "('preferred', 1.7866117998185356)\n",
      "('would', 1.7800361931945337)\n",
      "('letter', 1.7471764398945195)\n",
      "('advertisement', 1.745616202259257)\n",
      "('amp', 1.7449513447007763)\n",
      "('quantity', 1.7347282240644566)\n",
      "('customer', 1.7002476709883458)\n",
      "('insurance', 1.6980066452007645)\n",
      "('investment', 1.6974725095074923)\n",
      "('beverage', 1.687484058994261)\n",
      "('said', 1.6864292194861334)\n",
      "('vendor', 1.6774390851250913)\n",
      "('inch', 1.6701453713758756)\n",
      "('price', 1.6545678886784299)\n",
      "('way', 1.6398406783682629)\n",
      "('bid', 1.6194563219708815)\n",
      "('question', 1.6176026807455508)\n",
      "('service', 1.6145450276841793)\n",
      "('company', 1.5918115339221548)\n",
      "('sugar', 1.5825735353560848)\n",
      "('available', 1.5757432789789392)\n",
      "('care', 1.572582837367887)\n",
      "('make', 1.5669324357835384)\n",
      "('advertising', 1.562865833911921)\n",
      "('patent', 1.5564122275907688)\n",
      "('cigarette', 1.5506168469445702)\n",
      "('product', 1.542630193824669)\n",
      "('sale', 1.5327791569477847)\n",
      "('health', 1.5314134176535967)\n",
      "('customizable', 1.5283577648203746)\n",
      "('composed', 1.5246047246362175)\n",
      "('party', 1.5197841339374092)\n",
      "('internet', 1.4998049116307464)\n",
      "('user', 1.496548047927925)\n",
      "('project', 1.4891581259275686)\n",
      "('market', 1.4849231244927092)\n",
      "('wherein', 1.4811236370159515)\n",
      "('candle', 1.4631740039852978)\n",
      "('massage', 1.4440408694818203)\n",
      "('shirt', 1.435556648856496)\n",
      "('handle section', 1.418198967045373)\n",
      "('smartphone', 1.417558327599737)\n",
      "('estate', 1.4175338541484914)\n",
      "('patient', 1.4141952528902388)\n",
      "('odor', 1.4116994618603187)\n",
      "('displaying', 1.4013736458856278)\n",
      "('bandage', 1.3794668367348042)\n",
      "('game', 1.3736706414993327)\n",
      "('marketing', 1.3687688160751084)\n",
      "('account', 1.362154811684499)\n",
      "('ornament', 1.3604841253431113)\n",
      "('worn', 1.3595467096711837)\n",
      "('pocket', 1.3571703026357322)\n",
      "('absorbent', 1.3473474421863838)\n",
      "('food', 1.3454271279976686)\n",
      "('individual', 1.34332317561662)\n",
      "('air pump', 1.3379910613160184)\n",
      "('real estate', 1.3370041442636538)\n",
      "('display unit', 1.3315944898426082)\n",
      "('upper surface', 1.3313416583657158)\n",
      "('date', 1.33020288724121)\n",
      "('reward', 1.3301324690124554)\n",
      "('body part', 1.3296848155394967)\n",
      "('play', 1.328112781804742)\n",
      "('job', 1.3234399746027665)\n",
      "('purchaser', 1.3192940597270881)\n",
      "('ar', 1.3165553002903239)\n",
      "('metric', 1.3147637600364854)\n",
      "('baseball', 1.3130161953851829)\n",
      "('bead', 1.3104575443720576)\n",
      "('matching', 1.2995271056597062)\n",
      "('plastic', 1.2933335652852027)\n",
      "('support structure', 1.2907283462348613)\n",
      "('clothing', 1.2875330579139186)\n",
      "('doll', 1.2865320441977275)\n",
      "('fee', 1.2843518593375316)\n",
      "('payment', 1.278894560096818)\n",
      "('law', 1.2782890318626423)\n",
      "('eyelash', 1.2782417776636679)\n",
      "Logistic Regression Accuracy : 63.14%\n",
      "('invention', 4.009493507243418)\n",
      "('mean', 3.0043797231465694)\n",
      "('comprising', 2.675968480754923)\n",
      "('consumer', 2.602132549541746)\n",
      "('business', 2.5266868690148243)\n",
      "('comprised', 2.455674985167974)\n",
      "('financial', 2.2893282369253796)\n",
      "('made', 2.1550630933054618)\n",
      "('offer', 2.117851522232437)\n",
      "('customer', 2.0755391821798934)\n",
      "('owner', 2.071631998943583)\n",
      "('would', 2.05585039590654)\n",
      "('consists', 2.0265965702025346)\n",
      "('price', 1.9724868379830305)\n",
      "('advertisement', 1.972459597027594)\n",
      "('medical', 1.9214963555096032)\n",
      "('investment', 1.9017839459708579)\n",
      "('market', 1.8811748244261792)\n",
      "('portfolio', 1.8237338127017027)\n",
      "('social', 1.7744711095371135)\n",
      "('fund', 1.770005769638045)\n",
      "('transaction', 1.7540173663522192)\n",
      "('said', 1.7505382855670495)\n",
      "('account', 1.7335392046144904)\n",
      "('beverage', 1.6942991499052618)\n",
      "('insurance', 1.6917445862676355)\n",
      "('substance', 1.6804304997484316)\n",
      "('patent', 1.6441444380761623)\n",
      "('matching', 1.633066862027707)\n",
      "('internet', 1.6199217547967162)\n",
      "('power source', 1.6084458648301718)\n",
      "('make', 1.6012125576086498)\n",
      "('advantage', 1.591919549203278)\n",
      "('product', 1.588522128842707)\n",
      "('management', 1.5785170344721635)\n",
      "('customizable', 1.5663501878718047)\n",
      "('available', 1.5636934048471773)\n",
      "('project', 1.5616118321404746)\n",
      "('human', 1.5478659290346357)\n",
      "('odor', 1.540857244613044)\n",
      "('advertising', 1.5398707925998212)\n",
      "('campaign', 1.538636943469863)\n",
      "('electricity', 1.5325234502399891)\n",
      "('job', 1.5278731405851318)\n",
      "('wherein', 1.527761178726684)\n",
      "('bid', 1.5187460422632226)\n",
      "('staple', 1.5061294125673854)\n",
      "('database', 1.5043644016523101)\n",
      "('help', 1.5038695449991757)\n",
      "('providing', 1.496372995587518)\n",
      "('patient', 1.482076928876497)\n",
      "('real estate', 1.47694073707001)\n",
      "('shirt', 1.4743264644930205)\n",
      "('clothing', 1.4679144885625341)\n",
      "('coffee', 1.4677391384750529)\n",
      "('health', 1.4543371266224148)\n",
      "('prostate', 1.4455849826478075)\n",
      "('device second', 1.4383873928511173)\n",
      "('people', 1.4356419061955747)\n",
      "('body part', 1.431509917805644)\n",
      "('footwear', 1.4294691393760635)\n",
      "('payment', 1.4198023560138813)\n",
      "('provider', 1.4194344106988326)\n",
      "('require', 1.4173347348734786)\n",
      "('service', 1.4156756503834615)\n",
      "('quantity', 1.4143176882554689)\n",
      "('merchant', 1.393964022974265)\n",
      "('nail', 1.379533936246482)\n",
      "('amp', 1.3754322293507653)\n",
      "('purchaser', 1.3666695605465051)\n",
      "('brain', 1.3653758913455707)\n",
      "('bandage', 1.3598996422363585)\n",
      "('estate', 1.3533452468252276)\n",
      "('review', 1.3438909765303197)\n",
      "('flavor', 1.3426398897410496)\n",
      "('sale', 1.3406411847816857)\n",
      "('second end', 1.3379277115379993)\n",
      "('party', 1.336901638456787)\n",
      "('baseball', 1.3355311320302778)\n",
      "('enough', 1.33423076734208)\n",
      "('company', 1.333098372766582)\n",
      "('game', 1.3330090083551909)\n",
      "('preferred', 1.3240475464913164)\n",
      "('cigarette', 1.3208525545517649)\n",
      "('date', 1.3182595127635364)\n",
      "('individual', 1.3157827680827487)\n",
      "('sock', 1.3070521204444743)\n",
      "('composed', 1.3053124695571354)\n",
      "('drug', 1.3006254121114003)\n",
      "('consisting', 1.3002733797241541)\n",
      "('figure', 1.2972109013769295)\n",
      "('user head', 1.2969338355010427)\n",
      "('handle section', 1.2952803026868343)\n",
      "('vendor', 1.2942948418850722)\n",
      "('temperature control', 1.2900420999086786)\n",
      "('massage', 1.289553006827561)\n",
      "('letter', 1.2890933045128687)\n",
      "('reward', 1.2884370085182488)\n",
      "('fig', 1.2837749907326386)\n",
      "('therapy', 1.283060219100724)\n"
     ]
    }
   ],
   "source": [
    "word_dict = {}\n",
    "for i in range(2):\n",
    "  only_yes = patented_df.loc[patented_df['Patent_Target']==0,:].sample(52240)\n",
    "  only_no = patented_df.loc[patented_df['Patent_Target']==1,:]\n",
    "  all_data = pd.concat([only_yes,only_no],ignore_index=True)\n",
    "  tfidf_vect = TfidfVectorizer(ngram_range=(1,2))\n",
    "  train, test= train_test_split(all_data, test_size=0.2, random_state=42)\n",
    "  Xtrain, ytrain = train['clean_abstract'], train['Patent_Target']\n",
    "  Xtest, ytest = test['clean_abstract'], test['Patent_Target']\n",
    "  Xtrain_tfidf = tfidf_vect.fit_transform(Xtrain)\n",
    "  Xtest_tfidf = tfidf_vect.transform(Xtest)\n",
    "  lr = LogisticRegression(max_iter=1000)\n",
    "  vocab = tfidf_vect.vocabulary_\n",
    "  feature_names = {v: k for k, v in vocab.items()}\n",
    "  lr.fit(Xtrain_tfidf,ytrain)\n",
    "  lr.fit(Xtrain_tfidf,ytrain)\n",
    "  p1=lr.predict(Xtest_tfidf)\n",
    "  s1=accuracy_score(ytest,p1)\n",
    "  print(\"Logistic Regression Accuracy :\", \"{:.2f}%\".format(100*s1))\n",
    "  coef = lr.coef_[0]\n",
    "  features = sorted([(feature_names[idx], coef[idx]) for idx in range(len(coef))], key=lambda x: x[1], reverse=True)\n",
    "  for feature in features[:100]:\n",
    "    print(feature)\n",
    "    if feature[0] in word_dict:\n",
    "      word_dict[feature[0]]+=1\n",
    "    else:\n",
    "      word_dict[feature[0]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "executionInfo": {
     "elapsed": 292,
     "status": "ok",
     "timestamp": 1688218442270,
     "user": {
      "displayName": "Jonathan Vulcan",
      "userId": "13528297572882345759"
     },
     "user_tz": -180
    },
    "id": "UVcsaJAvp8uO"
   },
   "outputs": [],
   "source": [
    "mech_df = df[(df['one_if_small']==1) & (df['Patent_Target']!='pending') &(df['Parent_Catgeory']=='Mech_Engr')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 300,
     "status": "ok",
     "timestamp": 1688218481954,
     "user": {
      "displayName": "Jonathan Vulcan",
      "userId": "13528297572882345759"
     },
     "user_tz": -180
    },
    "id": "N_lRe2y5qVPs",
    "outputId": "f02ea737-25e7-46ae-b710-98b56bdef8b5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-93-75286fa79878>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mech_df['Patent_Target'] = mech_df['Patent_Target'].apply(lambda x: 1 if x =='abandoned' else 0)\n"
     ]
    }
   ],
   "source": [
    "mech_df['Patent_Target'] = mech_df['Patent_Target'].apply(lambda x: 1 if x =='abandoned' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "executionInfo": {
     "elapsed": 300,
     "status": "ok",
     "timestamp": 1688218505928,
     "user": {
      "displayName": "Jonathan Vulcan",
      "userId": "13528297572882345759"
     },
     "user_tz": -180
    },
    "id": "lKz1A0jfqbyq"
   },
   "outputs": [],
   "source": [
    "mech_df = mech_df[['clean_abstract','Patent_Target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 316,
     "status": "ok",
     "timestamp": 1688218598950,
     "user": {
      "displayName": "Jonathan Vulcan",
      "userId": "13528297572882345759"
     },
     "user_tz": -180
    },
    "id": "GDV7P89iqh2Z",
    "outputId": "57830ffe-f071-4f9b-9a9d-cb2d85eb292e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.566732\n",
       "1    0.433268\n",
       "Name: Patent_Target, dtype: float64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mech_df['Patent_Target'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 77931,
     "status": "ok",
     "timestamp": 1688218985577,
     "user": {
      "displayName": "Jonathan Vulcan",
      "userId": "13528297572882345759"
     },
     "user_tz": -180
    },
    "id": "JU5GYTb1qnaR",
    "outputId": "160b2b45-c5a9-4d9e-ed70-7b109b715432"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy : 59.99%\n",
      "('invention', 2.808603648677657)\n",
      "('comprising', 2.05150361020212)\n",
      "('nail', 1.7643181656124345)\n",
      "('staple', 1.6869492925366913)\n",
      "('pocket', 1.6717357908979233)\n",
      "('child', 1.6341514714095848)\n",
      "('mean', 1.6162592325224596)\n",
      "('hand', 1.5488661002742057)\n",
      "('word', 1.5185712255843116)\n",
      "('participant', 1.4907456399839982)\n",
      "('clothing', 1.463511591002645)\n",
      "('learning', 1.4049252625397421)\n",
      "('massage', 1.3957509834734012)\n",
      "('doll', 1.3709229662960525)\n",
      "('made', 1.3601876505258483)\n",
      "('shirt', 1.339807750468816)\n",
      "('medical', 1.318253107480822)\n",
      "('razor', 1.3118770414347516)\n",
      "('sock', 1.3009496924799746)\n",
      "('providing', 1.290529872256467)\n",
      "('invention provides', 1.2834206024534942)\n",
      "('hat', 1.2776069947122568)\n",
      "('necktie', 1.270204580171348)\n",
      "('wherein', 1.2685236079519717)\n",
      "('make', 1.2271900245902834)\n",
      "('protection', 1.2247949718732523)\n",
      "('present invention', 1.2230700484090715)\n",
      "('eyelash', 1.1996869170804891)\n",
      "('comprised', 1.193302600450676)\n",
      "('user', 1.1897450667205292)\n",
      "('body part', 1.1876544647009097)\n",
      "('gel', 1.1789480063533662)\n",
      "('wearer', 1.1628927433817653)\n",
      "('design', 1.1516207024170464)\n",
      "('individual', 1.146096071859648)\n",
      "('ultrasound', 1.1394013313105267)\n",
      "('wireless', 1.13508571774633)\n",
      "('letter', 1.129189458471413)\n",
      "('toothbrush', 1.1189111074260931)\n",
      "('new', 1.1183256086105575)\n",
      "('injection', 1.1057551893359863)\n",
      "('adhesive', 1.0905559811147485)\n",
      "('wrench', 1.0773096886925848)\n",
      "('student', 1.07595774367229)\n",
      "('person', 1.0753520193540904)\n",
      "('second end', 1.0726619013618226)\n",
      "('bandage', 1.061797456936979)\n",
      "('player', 1.0509146598652164)\n",
      "('material', 1.0499010937787268)\n",
      "('shoe', 1.0275359811927556)\n",
      "Logistic Regression Accuracy : 60.49%\n",
      "('invention', 2.6497362238922193)\n",
      "('comprising', 2.407661760967418)\n",
      "('staple', 1.878559399018908)\n",
      "('nail', 1.7929176067816626)\n",
      "('child', 1.78571429478817)\n",
      "('learning', 1.7355897339038546)\n",
      "('participant', 1.7259448745372312)\n",
      "('pocket', 1.6861064211278571)\n",
      "('massage', 1.6117190625158406)\n",
      "('human', 1.5455726400786791)\n",
      "('razor', 1.5141297420499225)\n",
      "('hand', 1.5053599256721282)\n",
      "('worn', 1.4843638980265663)\n",
      "('material', 1.461390853400263)\n",
      "('user', 1.4036188914242018)\n",
      "('shirt', 1.4010303672378681)\n",
      "('shoe', 1.3897313355398924)\n",
      "('necktie', 1.3493221772342205)\n",
      "('word', 1.3452878227902367)\n",
      "('hair', 1.3435693311557968)\n",
      "('present invention', 1.3052069656698495)\n",
      "('person', 1.2968234442105337)\n",
      "('easily', 1.2912082911095548)\n",
      "('may include', 1.2683918203838582)\n",
      "('doll', 1.2647140797739074)\n",
      "('student', 1.264208800062077)\n",
      "('towel', 1.2543889253554223)\n",
      "('footwear', 1.2465410566444168)\n",
      "('made', 1.2434114917305374)\n",
      "('design', 1.2297664049950485)\n",
      "('one embodiment', 1.227558507311544)\n",
      "('wig', 1.2129863627256812)\n",
      "('absorbent', 1.2000120459713648)\n",
      "('providing', 1.1920255436640188)\n",
      "('sock', 1.187551965545935)\n",
      "('comprised', 1.1797329236621)\n",
      "('food', 1.1779469191240723)\n",
      "('player', 1.1779200570029758)\n",
      "('color', 1.174599159428225)\n",
      "('invention provides', 1.173551672632799)\n",
      "('bag', 1.1622331221111095)\n",
      "('make', 1.160061338792413)\n",
      "('toe', 1.1553549896897621)\n",
      "('wrench', 1.148572293692997)\n",
      "('card', 1.1334037371409569)\n",
      "('mean', 1.126648058147086)\n",
      "('bottle', 1.1262702187210618)\n",
      "('would', 1.1216510655859118)\n",
      "('individual', 1.1174652402777026)\n",
      "('rubber', 1.10815909253249)\n"
     ]
    }
   ],
   "source": [
    "word_dict = {}\n",
    "for i in range(2):\n",
    "  only_yes = mech_df.loc[patented_df['Patent_Target']==0,:].sample(17500)\n",
    "  only_no = mech_df.loc[patented_df['Patent_Target']==1,:]\n",
    "  all_data = pd.concat([only_yes,only_no],ignore_index=True)\n",
    "  tfidf_vect = TfidfVectorizer(ngram_range=(1,2))\n",
    "  train, test= train_test_split(all_data, test_size=0.2, random_state=42)\n",
    "  Xtrain, ytrain = train['clean_abstract'], train['Patent_Target']\n",
    "  Xtest, ytest = test['clean_abstract'], test['Patent_Target']\n",
    "  Xtrain_tfidf = tfidf_vect.fit_transform(Xtrain)\n",
    "  Xtest_tfidf = tfidf_vect.transform(Xtest)\n",
    "  lr = LogisticRegression(max_iter=1000)\n",
    "  vocab = tfidf_vect.vocabulary_\n",
    "  feature_names = {v: k for k, v in vocab.items()}\n",
    "  lr.fit(Xtrain_tfidf,ytrain)\n",
    "  lr.fit(Xtrain_tfidf,ytrain)\n",
    "  p1=lr.predict(Xtest_tfidf)\n",
    "  s1=accuracy_score(ytest,p1)\n",
    "  print(\"Logistic Regression Accuracy :\", \"{:.2f}%\".format(100*s1))\n",
    "  coef = lr.coef_[0]\n",
    "  features = sorted([(feature_names[idx], coef[idx]) for idx in range(len(coef))], key=lambda x: x[1], reverse=True)\n",
    "  for feature in features[:50]:\n",
    "    print(feature)\n",
    "    if feature[0] in word_dict:\n",
    "      word_dict[feature[0]]+=1\n",
    "    else:\n",
    "      word_dict[feature[0]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 302,
     "status": "ok",
     "timestamp": 1688219280902,
     "user": {
      "displayName": "Jonathan Vulcan",
      "userId": "13528297572882345759"
     },
     "user_tz": -180
    },
    "id": "bFJVs11RtS90",
    "outputId": "4f5d06a0-0e7a-454b-86da-ae9e9e678df6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Male      0.834231\n",
       "Female    0.165769\n",
       "Name: Gender_Target, dtype: float64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['one_if_small']==1) & (df['Patent_Target']!='pending') &(df['Parent_Catgeory']=='Mech_Engr')]['Gender_Target'].value_counts(normalize=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPYm/Qcx/6ej0+Pnz7DwzsM",
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
